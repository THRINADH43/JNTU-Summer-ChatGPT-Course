{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/THRINADH43/JNTU-Summer-ChatGPT-Course/blob/main/Copy_of_ChatGPT_Lab02_NLTK_Questions_Thrinadh_Manubothu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Natural Language Processing\n",
        "\n",
        "## What is Natural Language Processing?\n",
        "\n",
        "Have you ever wondered how Siri understands what you say? Or how Google Translate can translate between hundreds of languages? These are just a couple of examples of NLP in action.\n",
        "\n",
        "You might be wondering, what exactly is NLP? Well, in simple terms, it's a field in artificial intelligence that helps computers understand, interpret, and respond to human language in a meaningful way.\n",
        "\n",
        "Cool, right?\n",
        "\n",
        "Applications of NLP are everywhere! We can see this field exploding recently with ChatGPT and other applications that use: sentiment analysis, chatbots, recommendation systems, and more!\n",
        "\n",
        "In this lab, we're going to start with some basics of NLP as building blocks.\n",
        "Don't worry if you're not a programming pro, we're going to guide you every step of the way. Here's what we're going to do:\n",
        "\n",
        "1. **Introduction to Python for NLP**: Python is a favorite language among NLP practitioners, and you're about to find out why! We'll get you started with some of the basic coding concepts you'll need for this lab.\n",
        "\n",
        "2. **Playing with NLTK library**: NLTK stands for Natural Language Toolkit, and it's a fantastic tool for dealing with human language data. It's going to be our best friend in this lab!\n",
        "\n",
        "3. **Diving into Text Processing**: We'll go through some important NLP techniques like tokenization, stemming, and lemmatization. These are just fancy terms for breaking down and simplifying text so a computer can understand it.\n",
        "\n",
        "Let's dive in..."
      ],
      "metadata": {
        "id": "r69KAdy3DARD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Lab: Getting Started with Python for NLP\n",
        "\n",
        "\n",
        "Python is a great language for NLP due to its simplicity and the powerful libraries it has.\n"
      ],
      "metadata": {
        "id": "ACyM64UZDDlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to NLTK library\n",
        "\n",
        "Let's begin by importing the Natural Language Toolkit (NLTK), one of the most popular libraries for NLP in Python. We'll also download a specific package called 'punkt'. 'punkt' is a pre-trained tokenizer model, allowing us to break down sentences into individual words or tokens, a fundamental step in many NLP tasks.\n"
      ],
      "metadata": {
        "id": "wSb0BVS6DP6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUBS4yFGDEQu",
        "outputId": "327fde20-ba3d-492e-ec36-3c4f7ffdc500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic text processing (tokenization, stemming, lemmatization)\n",
        "\n",
        "Now we'll perform tokenization, one of the most basic yet crucial steps in NLP. Tokenization is the process of splitting a sentence into individual words or 'tokens'. Each token is like a meaningful piece of a puzzle, and together they form the full picture - the sentence. Let's try tokenizing a simple sentence and see what we get.\n"
      ],
      "metadata": {
        "id": "AqeWaudAHHHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"This is an example sentence for tokenization.\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWL_a-jXHIQz",
        "outputId": "57571e85-397b-48da-d6c9-bb14b086a308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'an', 'example', 'sentence', 'for', 'tokenization', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Next up, we have two super useful techniques: 'stemming' and 'lemmatization'.\n",
        "\n",
        "#### Stemming\n",
        "\n",
        "**Stemming** is like trimming a word down to its root form. For example, 'running', 'runs', and 'ran' all come from the root word 'run'. Stemming is a technique used to extract the base form of words by removing any affixes (like prefixes or suffixes).\n",
        "\n",
        "This helps us standardize words and can improve text understanding, especially in search queries.\n",
        "\n",
        "NLTK provides several off-the-shelf stemmers, and for this example, we'll use the Porter stemmer, one of the oldest and simplest stemming algorithms.\n",
        "\n"
      ],
      "metadata": {
        "id": "WpccdrLyHJtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed = [stemmer.stem(token) for token in tokens]\n",
        "print(stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0lRbhaJHM2S",
        "outputId": "c13ee779-79cd-4dbf-b178-1d9b506240d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thi', 'is', 'an', 'exampl', 'sentenc', 'for', 'token', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As you may recognize, stemming is a bit crude and might give us a root that's not even a real word! That's where lemmatization comes in.\n",
        "\n",
        "#### Lemmatization\n",
        "\n",
        "**Lemmatization** is another technique that is a bit smarter and gives us the basic form of a word, also known as the 'lemma', that's sure to be a real word. So, 'is', 'am', and 'are' would all become 'be'."
      ],
      "metadata": {
        "id": "PqpN32AfHOwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "print(lemmatized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaeaHy4FHTVz",
        "outputId": "4f93289d-e748-402e-ce7f-fe4071b04793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'more', 'complex', 'sentence', 'that', 'I', 'am', 'running', 'to', 'demonstrate', 'lemmatization', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"“In linguistic morphology, inflection is a process of word formation, \\\n",
        "        in which a word is modified to express different grammatical categories \\\n",
        "        such as tense, case, voice, aspect, person, number, gender, mood, animacy, and definiteness.”\"\n",
        "tokens = word_tokenize(text)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "print(lemmatized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KbRH5_COziM",
        "outputId": "08ecde74-a5e7-4859-c02e-17652cb9fa12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['“', 'In', 'linguistic', 'morphology', ',', 'inflection', 'is', 'a', 'process', 'of', 'word', 'formation', ',', 'in', 'which', 'a', 'word', 'is', 'modified', 'to', 'express', 'different', 'grammatical', 'category', 'such', 'a', 'tense', ',', 'case', ',', 'voice', ',', 'aspect', ',', 'person', ',', 'number', ',', 'gender', ',', 'mood', ',', 'animacy', ',', 'and', 'definiteness', '.', '”']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming vs Lemmatization showdown!\n",
        "\n",
        "\n",
        "| Technique | Type | Points |\n",
        "| --- | --- | --- |\n",
        "| **Stemming** | Pros | **Boosts speed**: Helps computer programs run faster. |\n",
        "| | | **Groups words**: Lumps together words that mean similar things. |\n",
        "| | | **Simplifies analysis**: Makes it easier to understand and compare texts. |\n",
        "| | Cons | **Can mix up words**: Sometimes, wrongly groups different words together. |\n",
        "| | | **Can split similar words**: At times, fails to group words that are similar. |\n",
        "| | | **Struggles with complex languages**: Languages with complicated grammar can pose challenges. |\n",
        "| **Lemmatization** | Pros | **More accurate**: Gives more precise results because it understands the context and grammar. |\n",
        "| | Cons | **Takes longer**: Compared to stemming, lemmatization takes more time because it does a more thorough job. |\n",
        "\n"
      ],
      "metadata": {
        "id": "ECWAOTiGQHJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YOU TRY:"
      ],
      "metadata": {
        "id": "08SeDOzyHTID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1:** Tokenize the following sentence: \"This is an example sentence. It is used for the NLP lab.\"\n"
      ],
      "metadata": {
        "id": "KsAqKLhUCwBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"This is yet another example sentence that is being used for the NLP lab.\"\n",
        "### YOUR CODE HERE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvJz4Mq4Cxpt",
        "outputId": "6ff2c1b2-a7e7-44a4-8452-0eb7b04ed266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'yet', 'another', 'example', 'sentence', 'that', 'is', 'being', 'used', 'for', 'the', 'NLP', 'lab', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Exercise 2:** Stem and lemmatize the tokens obtained in the previous step.\n"
      ],
      "metadata": {
        "id": "ZIgV_ObDCeNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "720JNlm6Cn9H",
        "outputId": "62fe4528-5804-41e1-af6b-7fda280ce3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed:  ['thi', 'is', 'yet', 'anoth', 'exampl', 'sentenc', 'that', 'is', 'be', 'use', 'for', 'the', 'nlp', 'lab', '.']\n",
            "Lemmatized:  ['This', 'is', 'yet', 'another', 'example', 'sentence', 'that', 'is', 'being', 'used', 'for', 'the', 'NLP', 'lab', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part of Speech (POS) Tagging\n",
        "POS tagging is the task of labeling the words in a sentence with their appropriate part of speech (noun, verb, adjective, etc.). NLTK library has a method for doing this:\n",
        "\n"
      ],
      "metadata": {
        "id": "zJQ83IGeIYBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag\n",
        "\n",
        "tokens = word_tokenize(\"This is an example sentence for POS tagging.\")\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "print(tagged_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acJui6PrIg-1",
        "outputId": "f7e48d10-9e19-444a-dbb4-cfe8c0a17d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'DT'), ('is', 'VBZ'), ('an', 'DT'), ('example', 'NN'), ('sentence', 'NN'), ('for', 'IN'), ('POS', 'NNP'), ('tagging', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of the sentence \"This is an example sentence for POS tagging.\":\n",
        "\n",
        "\n",
        "- \"This/DT\": \"This\" is a determiner.\n",
        "\n",
        "- \"is/VBZ\": \"is\" is a verb, 3rd person singular present.\n",
        "\n",
        "- \"an/DT\": \"an\" is a determiner.\n",
        "\n",
        "- \"example/NN\": \"example\" is a noun.\n",
        "\n",
        "- \"sentence/NN\": \"sentence\" is a noun.\n",
        "\n",
        "- \"for/IN\": \"for\" is a preposition.\n",
        "\n",
        "- \"(ORGANIZATION POS/NNP)\": \"POS\" is recognized as a proper noun and it is classified as an organization. The \"ORGANIZATION\" tag is a part of NER and indicates that \"POS\" is being recognized as the name of an organization.\n",
        "\n",
        "- \"tagging/NN\": \"tagging\" is a noun.\n",
        "\n",
        "- \"./.\": This signifies the end of the sentence.\n"
      ],
      "metadata": {
        "id": "cJOYZ9IuLOg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common POS Tags\n",
        "The tags used are from the Penn Treebank Project, a widely used resource for training NLP models. The tagset includes:\n",
        "\n",
        "\n",
        "- NN: noun, singular or mass\n",
        "\n",
        "- DT: determiner\n",
        "\n",
        "- VB: verb, base form\n",
        "\n",
        "- WRB: Wh-adverb\n",
        "\n",
        "- JJ: adjective\n",
        "\n",
        "- MD: modal\n",
        "\n",
        "- IN: preposition or subordinating conjunction\n",
        "\n",
        "\"S\" at the beginning stands for Sentence, indicating the start of a sentence. This notation is commonly used in NLP for parsing sentences into their grammatical structure.\n",
        "\n",
        "Please note that part-of-speech tagging is not always 100% accurate, especially with ambiguous sentences or words that can serve multiple functions depending on the context. For example, in this sentence, \"chuck\" and \"woodchuck\" could have been tagged differently depending on the interpretation."
      ],
      "metadata": {
        "id": "enjXaw-1LSUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Named Entity Recognition (NER)\n",
        "NER is the task of finding named entities like person names, geographic locations, company names, etc."
      ],
      "metadata": {
        "id": "gwE97TSTIgUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "from nltk import ne_chunk\n",
        "\n",
        "ne_tree = ne_chunk(tagged_tokens)\n",
        "print(ne_tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-ae-Y_wImMr",
        "outputId": "647edd46-895d-40cc-87e6-3af97be5e793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  This/DT\n",
            "  is/VBZ\n",
            "  an/DT\n",
            "  example/NN\n",
            "  sentence/NN\n",
            "  for/IN\n",
            "  (ORGANIZATION POS/NNP)\n",
            "  tagging/NN\n",
            "  ./.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YOU TRY:\n",
        "\n",
        "**Exercise 3:** Go through the process (using different variable names) to tag the parts of speech in the following sentence:\n"
      ],
      "metadata": {
        "id": "DKXAB4y2I5_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "woodchuck = \"how much wood could a woodchuck named Mr. WoodChuck chuck if a woodchuck could chuck wood\"\n",
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgvB4z7eJLWJ",
        "outputId": "60b9ca3a-a867-4711-91f4-0f75d6379759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('how', 'WRB'), ('much', 'JJ'), ('wood', 'NN'), ('could', 'MD'), ('a', 'DT'), ('woodchuck', 'NN'), ('named', 'VBN'), ('Mr.', 'NNP'), ('WoodChuck', 'NNP'), ('chuck', 'VBZ'), ('if', 'IN'), ('a', 'DT'), ('woodchuck', 'NN'), ('could', 'MD'), ('chuck', 'VB'), ('wood', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4:** Now perform NER (named entity recognition on the sentence above) and consider what NER performs in that sentence or how it might be working."
      ],
      "metadata": {
        "id": "ER9Ky3ZjJh6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTkvBrbBJoaC",
        "outputId": "c2e34339-b2fa-4989-927c-396d51121bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  how/WRB\n",
            "  much/JJ\n",
            "  wood/NN\n",
            "  could/MD\n",
            "  a/DT\n",
            "  woodchuck/NN\n",
            "  named/VBN\n",
            "  (PERSON Mr./NNP WoodChuck/NNP)\n",
            "  chuck/VBZ\n",
            "  if/IN\n",
            "  a/DT\n",
            "  woodchuck/NN\n",
            "  could/MD\n",
            "  chuck/VB\n",
            "  wood/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice on Your Own\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qYLggsmqCb4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 5:** Write a function that takes a sentence as input and returns the tokens, stemmed words, and lemmatized words."
      ],
      "metadata": {
        "id": "67Euz3iHCiAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"This is another example sentence for practice.\"\n",
        "### YOUR CODE HERE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPx2yqHOCaS_",
        "outputId": "201d8fea-125d-4958-ecb2-d8091e041c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['This', 'is', 'another', 'example', 'sentence', 'for', 'practice', '.']\n",
            "Stemmed: ['thi', 'is', 'anoth', 'exampl', 'sentenc', 'for', 'practic', '.']\n",
            "Lemmatized: ['This', 'is', 'another', 'example', 'sentence', 'for', 'practice', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 6:** Write a function that takes a sentence, tokenizes it, performs POS tagging and NER, and returns the result."
      ],
      "metadata": {
        "id": "9WmzP5zXCVa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Elon Musk, the CEO of SpaceX, announced a new mission to Mars.\"\n",
        "### YOUR CODE HERE\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsJC9YE3CSdD",
        "outputId": "ab120a10-502f-4e93-82fe-d4e3565ac1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON Elon/NNP)\n",
            "  (GPE Musk/NNP)\n",
            "  ,/,\n",
            "  the/DT\n",
            "  (ORGANIZATION CEO/NNP)\n",
            "  of/IN\n",
            "  (ORGANIZATION SpaceX/NNP)\n",
            "  ,/,\n",
            "  announced/VBD\n",
            "  a/DT\n",
            "  new/JJ\n",
            "  mission/NN\n",
            "  to/TO\n",
            "  (PERSON Mars/NNP)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus section and Preview for Next Time!\n",
        "\n",
        "See if you can look through this code and think about what it does:"
      ],
      "metadata": {
        "id": "7v3CYHliZ4b0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.corpus import webtext\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "\n",
        "# Initialize stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "\n",
        "# Get the web and chat text corpus\n",
        "text = webtext.raw()\n",
        "\n",
        "# Tokenize text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "# Perform stemming\n",
        "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "# Perform lemmatization\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "# Identify most common words\n",
        "most_common_stemmed_words = Counter(stemmed_tokens).most_common(10)\n",
        "most_common_lemmatized_words = Counter(lemmatized_tokens).most_common(10)\n",
        "\n",
        "print(\"Most common stemmed words: \", most_common_stemmed_words)\n",
        "print(\"Most common lemmatized words: \", most_common_lemmatized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3WpxZ22TWTQ",
        "outputId": "65c168f6-a6d2-4ae9-8c7d-bc8616b3ddf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common stemmed words:  [('.', 16479), (':', 14328), (',', 12427), ('i', 7805), ('?', 4743), ('!', 4417), ('*', 3944), ('#', 3777), (\"n't\", 3481), (\"'s\", 3198)]\n",
            "Most common lemmatized words:  [('.', 16479), (':', 14328), (',', 12427), ('I', 7805), ('?', 4743), ('!', 4417), ('*', 3944), ('#', 3777), (\"n't\", 3477), (\"'s\", 3181)]\n"
          ]
        }
      ]
    }
  ]
}